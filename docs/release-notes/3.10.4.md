# Release notes for Gluster 3.10.4

This is a bugfix release. The release notes for [3.10.0](3.10.0.md) ,
[3.10.1](3.10.1.md), [3.10.2](3.10.2.md) and [3.10.3](3.10.3.md)
contain a listing of all the new features that were added and
bugs fixed in the GlusterFS 3.10 stable release.

## Major changes, features and limitations addressed in this release
1. No Major changes


## Major issues
1. Expanding a gluster volume that is sharded may cause file corruption
- Sharded volumes are typically used for VM images, if such volumes are
expanded or possibly contracted (i.e add/remove bricks and rebalance)
there are reports of VM images getting corrupted.
- Status of this bug can be tracked here, [#1426508](https://bugzilla.redhat.com/1426508)
2. Brick multiplexing is being tested and fixed aggressively but we still have a
   few crashes and memory leaks to fix.
3. Another rebalance related bug is being worked upon [#1467010](https://bugzilla.redhat.com/1467010)


## Bugs addressed

A total of 18 patches have been merged, addressing 13 bugs:

- [#1457732](https://bugzilla.redhat.com/1457732): "split-brain observed [Input/output error]" error messages in samba logs during parallel rm -rf
- [#1459760](https://bugzilla.redhat.com/1459760): Glusterd segmentation fault in ' _Unwind_Backtrace' while running peer probe
- [#1460649](https://bugzilla.redhat.com/1460649): posix-acl: Whitelist virtual ACL xattrs
- [#1460914](https://bugzilla.redhat.com/1460914): Rebalance estimate time sometimes shows negative values
- [#1460993](https://bugzilla.redhat.com/1460993): Revert CLI restrictions on running rebalance in VM store use case
- [#1461019](https://bugzilla.redhat.com/1461019): [Ganesha] : Grace period is not being adhered to on RHEL 7.4; Clients continue running IO even during grace.
- [#1462080](https://bugzilla.redhat.com/1462080): [Bitrot]: Inconsistency seen with 'scrub ondemand' - fails to trigger scrub
- [#1463623](https://bugzilla.redhat.com/1463623): [Ganesha]Bricks got crashed while running posix compliance test suit on V4 mount
- [#1463641](https://bugzilla.redhat.com/1463641): [Ganesha] Ganesha service failed to start on new node added in existing ganeshacluster
- [#1464078](https://bugzilla.redhat.com/1464078): with AFR now making both nodes to return UUID for a file will result in georep consuming more resources
- [#1466852](https://bugzilla.redhat.com/1466852): assorted typos and spelling mistakes from Debian lintian
- [#1466863](https://bugzilla.redhat.com/1466863): dht_rename_lock_cbk crashes in upstream regression test
- [#1467269](https://bugzilla.redhat.com/1467269): Heal info shows incorrect status
